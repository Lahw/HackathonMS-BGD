{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> IMPORT </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTILS FUNCTION\n",
    "def _getRidOfNonAlphaNumeric (string):\n",
    "    return re.sub('[^0-9a-zA-Z]+', '', string)\n",
    "    \n",
    "def _removeSpecialCarFromText(text):\n",
    "    return text.replace(u'\\t', u'').replace(u'\\r', u'').replace(u'\\u0153', u'oe').replace(u'\\xc2', u'').replace(u'\\xa0', u'').replace(u'\\xe2', u'').replace(u'\\x82', u'').replace(u'\\xac', u'').replace(u'\\u20ac', u'').replace(u'\\n', u'').replace(u'\\xc0', u'A').replace(u'\\xe9', u'e').replace(u'\\xe0', u'a').replace(u'\\xe7',u'c').replace(u'\\xe8',u'e').replace(u'\\xf4',u'o').replace(u'\\xee',u'i').replace(u'\\xc9',u'E').replace(u'\\xd4',u'O').replace(u'\\xea',u'e').replace(u'\\xfb',u'u').replace(u'\\u2019',u' ')\n",
    "\n",
    "def _getIndices(my_list, things_to_find):\n",
    "    return [i for i, x in enumerate(my_list) if any(thing in x for thing in things_to_find)]\n",
    "\n",
    "def _constructVector(dimensions, data):\n",
    "    res = [0]*len(dimensions)\n",
    "    for indice in _getIndices(dimensions, data):\n",
    "        res[indice] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PARSING THE NUMBERS </h1>\n",
    "<p> On scrape le site de The Numbers pour recuperer le buget des films </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urlTheNumbers = 'http://www.the-numbers.com/movie/budgets/all'\n",
    "nameCsv = 'thenumbers.csv'\n",
    "\n",
    "soup = BeautifulSoup(requests.get(urlTheNumbers).text.encode('utf-8'), 'html.parser')\n",
    "columns = ['Release Date', 'Movie', 'Production Budget', 'Domestic Gross', 'Worldwide Gross']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "nbFilms = 5028\n",
    "for i in range(2, nbFilms*2 + 1, 2):\n",
    "    year = soup.select('table tr:nth-of-type(' + str(i) + ') td:nth-of-type(2)')[0].find('a').next\n",
    "    movie = _removeSpecialCarFromText(soup.select('table tr:nth-of-type(' + str(i) + ') td:nth-of-type(3)')[0].find('a').next)\n",
    "    prodBudget = _getRidOfNonAlphaNumeric(soup.select('table tr:nth-of-type(' + str(i) + ') td:nth-of-type(4)')[0].next)\n",
    "    domesticGross = _getRidOfNonAlphaNumeric(soup.select('table tr:nth-of-type(' + str(i) + ') td:nth-of-type(5)')[0].next)\n",
    "    worldwideGross = _getRidOfNonAlphaNumeric(soup.select('table tr:nth-of-type(' + str(i) + ') td:nth-of-type(6)')[0].next)\n",
    "    df.loc[i/2-1] = [year, movie, prodBudget, domesticGross, worldwideGross]\n",
    "    if i % 300 == 0:\n",
    "        print 'Save ' + str(i)\n",
    "        df.to_csv(nameCsv, encoding='utf-8')\n",
    "\n",
    "df.to_csv(nameCsv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> NB tickets vendus et sommes recu par film par annee </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urlTheNumbers = 'http://www.the-numbers.com/market/{year}/top-grossing-movies'\n",
    "years = range(1995, 2016)\n",
    "nameCsv = 'thenumberTopGrossingMovies.csv'\n",
    "\n",
    "columns = ['Year', 'Rank', 'Movie', 'Release Date', 'Distributor', 'Genre', 'MPAA', 'Gross', 'Tickets Sold']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "cpt = 1\n",
    "for year in years:\n",
    "    url = urlTheNumbers.format(year=year)\n",
    "    htmlUrl = requests.get(url).text.encode('utf-8')\n",
    "    soup = BeautifulSoup(htmlUrl, 'html.parser')\n",
    "    firstLoop = True\n",
    "    for row in soup.findAll('tr'):\n",
    "        if firstLoop:\n",
    "            firstLoop = False\n",
    "        else:\n",
    "            ending = re.search(r'Total Gross of All Movies', row.text)\n",
    "            if ending is None:\n",
    "                res = [year]\n",
    "                for cell in row.findAll('td'):\n",
    "                    hasLink = cell.find('a')\n",
    "                    if hasLink is None:\n",
    "                        res.append(cell.next)\n",
    "                    else:\n",
    "                        res.append(hasLink.next)\n",
    "                res[-1] = int(_getRidOfNonAlphaNumeric(res[-1]))\n",
    "                res[-2] = int(_getRidOfNonAlphaNumeric(res[-2]))\n",
    "                res[2] = _removeSpecialCarFromText(res[2])\n",
    "                res[3] = _removeSpecialCarFromText(res[3])\n",
    "                df.loc[cpt] = res\n",
    "                cpt += 1\n",
    "                if cpt % 100 == 0:\n",
    "                    print 'Save : ' + str(cpt)\n",
    "                    df.to_csv(nameCsv, encoding='utf-8')    \n",
    "            else:\n",
    "                break\n",
    "df.to_csv(nameCsv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> On merge les deux dataframe et on les regroupes par films </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "df1 = pd.read_csv('thenumbers.csv')\n",
    "df2 = pd.read_csv('thenumberTopGrossingMovies.csv')\n",
    "df = pd.merge(df1, df2, left_on=['Movie', 'Release Date'], right_on=['Movie', 'Release Date'])\n",
    "\n",
    "# Clean\n",
    "df['Sum Tickets Sold Gross'] = df['Gross'].groupby(df['Movie']).transform('sum')\n",
    "df['Rentabilite Tickets'] = df['Sum Tickets Sold Gross'] / df['Production Budget']\n",
    "df['Rentabilite'] = df['Worldwide Gross'] / df['Production Budget']\n",
    "df = df.drop_duplicates('Movie')\n",
    "df = df[['Movie', 'Rentabilite', 'Rentabilite Tickets']]\n",
    "df.to_csv('cleanAllMovies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Creation des colonnes <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS_MOVIES = ['Movie', 'ratingValue', 'ratingCount', 'reviewUser', 'reviewCritic', 'genreMovie', 'acteurs', 'description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Parsing de IMDB pour recuperer pour chacun de nos films les notes et les acteurs ainsi qu un resume </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeSpecialCarFromText(text):\n",
    "    return text.replace(u',', u'').replace(u' user',u'').replace(u' critic', '').replace(u' ', u'')#.replace(u'\\r', u'').replace(u'\\u0153', u'oe').replace(u'\\xc2', u'').replace(u'\\xa0', u'').replace(u'\\xe2', u'').replace(u'\\x82', u'').replace(u'\\xac', u'').replace(u'\\u20ac', u'').replace(u'\\n', u'').replace(u'\\xc0', u'A').replace(u'\\xe9', u'e').replace(u'\\xe0', u'a').replace(u'\\xe7',u'c').replace(u'\\xe8',u'e').replace(u'\\xf4',u'o').replace(u'\\xee',u'i').replace(u'\\xc9',u'E').replace(u'\\xd4',u'O').replace(u'\\xea',u'e').replace(u'\\xfb',u'u').replace(u'\\u2019',u' ')\n",
    "\n",
    "def getSoupFromUrl(url):\n",
    "    request = requests.get(url)\n",
    "    return BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "def buildURL(movie_name):\n",
    "    return 'http://www.imdb.com/find?ref_=nv_sr_fn&q=' + movie_name + '&s=all'\n",
    "\n",
    "def getURLMovie(soup):\n",
    "    if soup.find('table', {'class' : 'findList'}) is not None:\n",
    "        hrefMovies = soup.find('table', {'class' : 'findList'}).findAll('tr')\n",
    "        hrefMovie = ''\n",
    "        for mov in hrefMovies:\n",
    "            if len(mov.findAll('td')) > 1:\n",
    "                title = mov.findAll('td')[1].text.strip()\n",
    "                if title.count('(') == 1 and title.count(')') == 1:\n",
    "                    hrefMovie = mov.findAll('td')[1].find('a')['href']\n",
    "                    break\n",
    "            else:\n",
    "                hrefMovie = ''\n",
    "    else:\n",
    "        hrefMovie = ''\n",
    "    return 'http://www.imdb.com' + hrefMovie\n",
    "\n",
    "def getInformationFromMovie(soup_movie):\n",
    "    \n",
    "    # GET NOTATION OF THE MOVIE\n",
    "    if (soup_movie.find('span', itemprop='ratingValue') is not None):\n",
    "        ratingValue = float(soup_movie.find('span', itemprop='ratingValue').text)\n",
    "    else:\n",
    "        ratingValue = 0\n",
    "    if (soup_movie.find('span', itemprop='ratingCount') is not None):\n",
    "        ratingCount = int(removeSpecialCarFromText(soup_movie.find('span', itemprop='ratingCount').text))\n",
    "    else:\n",
    "        ratingCount = 0\n",
    "    if (soup_movie.findAll('span', itemprop='reviewCount') is not None):\n",
    "        list_reviews = soup_movie.findAll('span', itemprop='reviewCount')\n",
    "        if (len(list_reviews) > 1):\n",
    "            reviewUser = int(removeSpecialCarFromText(list_reviews[0].text))\n",
    "            reviewCritic = int(removeSpecialCarFromText(list_reviews[1].text))\n",
    "        else:\n",
    "            reviewUser = 0\n",
    "            reviewCritic = 0\n",
    "    else:\n",
    "        list_reviews = []\n",
    "        reviewUser = 0\n",
    "        reviewCritic = 0\n",
    "    \n",
    "    # GENRE MOVIE\n",
    "    if (soup_movie.find('div', itemprop='genre') is not None):\n",
    "        genreSoup = soup_movie.find('div', itemprop='genre')\n",
    "        list_genres = genreSoup.findAll('a')\n",
    "        genreMovie = [removeSpecialCarFromText(genre.text).strip().lower() for genre in list_genres]\n",
    "    else:\n",
    "        genreMovie = []\n",
    "    \n",
    "    # CASTING LIST\n",
    "    if (soup_movie.find('div', {'id':'titleCast'}) is not None):\n",
    "        soup_acteur = soup_movie.find('div', {'id':'titleCast'})\n",
    "        list_acteurs = soup_acteur.findAll('span', itemprop='name')\n",
    "        acteurs = [acteur.text.strip().lower() for acteur in list_acteurs]\n",
    "    else:\n",
    "        acteurs = []\n",
    "    \n",
    "    # DIRECTOR\n",
    "    if (soup_movie.find('div', itemprop='director') is not None):\n",
    "        director = soup_movie.find('div', itemprop='director').find('span').text\n",
    "        acteurs.insert(0, director.strip().lower())\n",
    "    \n",
    "    for acteur in acteurs:\n",
    "        if acteur not in list_acteur_all:\n",
    "            list_acteur_all.append(acteur)\n",
    "    \n",
    "    # MOVIE DESCRIPTION\n",
    "    if (soup_movie.find('div', itemprop='description') is not None):\n",
    "        description = soup_movie.find('div', itemprop='description').find('p').text\n",
    "        description = description.split(\"Written by\")[0]\n",
    "        description = description.strip()\n",
    "    else:\n",
    "        description = ''\n",
    "    \n",
    "    return ratingValue, ratingCount, reviewUser, reviewCritic, genreMovie, acteurs, description\n",
    "\n",
    "# READ CSV MOVIE\n",
    "csv_file = pd.read_csv('allMovies.csv', sep=',')\n",
    "# print csv_file.head()\n",
    "\n",
    "csv_file['Movie'] = csv_file['Movie'].str.replace(r' ', '+')\n",
    "csv_file['Movie'] = csv_file['Movie'].str.replace(r':', '')\n",
    "list_of_movies = csv_file['Movie'].unique()\n",
    "\n",
    "\n",
    "list_acteur_all = []\n",
    "# CREATE DATAFRAME \n",
    "df_movie = pd.DataFrame(columns=COLUMNS_MOVIES)\n",
    "indice = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Utilisation des threads pour faire le parsing sur IMDB </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DisplayThread(Thread):\n",
    "\n",
    "    #Constructeur\n",
    "    def __init__(self, numThread, movies):\n",
    "        Thread.__init__(self)\n",
    "        self.numThread = numThread\n",
    "        self.movies = movies\n",
    "\n",
    "    #On definit notre run\n",
    "    def run(self):\n",
    "        #On recupere le nb de films traites par thread\n",
    "        movie_by_thread = len(self.movies)/nb_thread\n",
    "        #L indice du premier film traite\n",
    "        first_movie = self.numThread * movie_by_thread\n",
    "        #L indice du dernier\n",
    "        last_movie = (self.numThread + 1) * movie_by_thread\n",
    "        #On effectue notre parsing sur cette partie de films\n",
    "        indice = self.numThread * movie_by_thread\n",
    "        for movie in self.movies[first_movie:last_movie]:\n",
    "            url = buildURL(movie)\n",
    "            soup = getSoupFromUrl(url)\n",
    "            url_movie = getURLMovie(soup)\n",
    "\n",
    "            if url_movie is not '':\n",
    "                soup_movie = getSoupFromUrl(url_movie)\n",
    "\n",
    "                ratingValue, ratingCount, reviewUser, reviewCritic, genreMovie, acteurs, description = getInformationFromMovie(soup_movie)\n",
    "\n",
    "                df_movie.loc[indice] = [movie, ratingValue, ratingCount, reviewUser, reviewCritic, genreMovie, acteurs, description]\n",
    "\n",
    "                if (indice % 10) == 0:\n",
    "                    print 'Save ' + str(indice)\n",
    "                    df_movie.to_csv('movieRate.csv', encoding='utf-8')\n",
    "            print indice\n",
    "            indice+=1\n",
    "\n",
    "nb_thread = os.sysconf(\"SC_NPROCESSORS_ONLN\") * 2\n",
    "print nb_thread\n",
    "threads = []\n",
    "for i in range(0,nb_thread):\n",
    "    t = DisplayThread(i, list_of_movies)\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
